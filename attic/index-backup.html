<!DOCTYPE html>
<html>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<meta charset="utf-8">
<title>Owen Hindley</title>
<meta name="description"
	content="Owen Hindley creates experiences for VR, live theatre, installations, games, performance and the web using software, electronics and sometimes sound.">
<meta name="author" content="Owen Hindley">
<meta property="og:url" content="http://www.owenhindley.co.uk">
<meta property="og:type" content="website">
<meta property="og:title" content="Owen Hindley">
<meta property="og:description"
	content="Owen Hindley creates experiences for VR, live theatre, installations, games, performance and the web using software, electronics and sometimes sound.">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:title" content="Owen Hindley Portfolio">
<meta name="twitter:description"
	content="Owen Hindley creates experiences for VR, live theatre, installations, games, performance and the web using software, electronics and sometimes sound.">

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" href="images/favicon.png">

<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="http://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css">

<link rel="stylesheet" href="css/normalize.css">
<link rel="stylesheet" href="css/main.css">




<body>
	

		<header>
			<h1>OWEN HINDLEY</h1>
			<a id="twitter-link" href="http://twitter.com/owen_hindley" target="_blank">t</a>
			<a id="github-link" href="http://github.com/owenhindley" target="_blank">g</a>
			<h6>
				owenhindley at hotmail dot com<br>
				+354 762 0292<br>
			</h6>
			<p>Hi ✋I'm Owen, and I create experiences for VR, live
				theatre, installations, games,
				performance and the web using software, electronics and sometimes sound.</p>                
			<p>I'm co-founder of <a href="http://huldufugl.is/" target="_blank">Huldufugl</a>, creating
				immersive theatrical environments in both the real world
				and the&nbsp;virtual.</p>
			<p>Here's the story so&nbsp;far..</p>
		</header>
	   
		<nav>
			<label><input type="checkbox" id="check-recent" checked>Recent</input></label>
			<label><input type="checkbox" id="check-works">Works</input></label>
			<label><input type="checkbox" id="check-collaboration">Collaborations</input></label>
			<label><input type="checkbox" id="check-talks">Talks &amp; Education</input></label>
		</nav>

		<main>

			<!-- TEMPLATE -->
			<!-- <article class="works recent" id="name">
				<header>
					<h3>TITLE</h3>
					<summary>Subject<span class="divider">x</span> Client</summary>
					<ol>
						<li>2021-2022</li>
						<li>What you did</li>
						<li>Tools</li>
					</ol>
				</header>
				<section>
					<section>
					<img src="./images/projects/HiddenWorld-coverDesign.png" alt="vrShort-portfolio" width="610"
									height="400" class="alignleft" />
					</section>
					<section>
						<p>Lorem Ipsum</p>
						
					</section>
					<section>
						<p>Lorem Ipsum</p>          
					</section>
					<section>
						<ul>
							<li>Link to a thing : <a href="http://www.huldufugl.is/" target="_blank">➩</a></li>
						   
						</ul>
					</section>
				</section>
			</article> -->

			<!-- PARALLEL PEOPLE -->
			<article class="works recent" id="parallel-people">
				<header>
					<h3>Parallel People / Hliðstætt Fólk</h3>
					<summary>Interactive VR theatre <span class="divider">x</span> Huldufugl</summary>
					<ol>
						<li>2021-2022</li>
						<li>Design, development, direction</li>
						<li>Unity, Houdini</li>
					</ol>
				</header>
				<section>
					<section>
					<img src="./images/projects/see-you-soon.jpg" alt="see-you-soon-portfolio" width="610"
									class="alignleft" />
					</section>
					<section>
						<p>Lorem Ipsum</p>
						
					</section>
					<section>
						<p>Lorem Ipsum</p>          
					</section>
					<section>
						<ul>
							<li>Huldufugl : <a href="http://www.huldufugl.is/" target="_blank">➩</a></li>						   
						</ul>
					</section>
				</section>
			</article>

			<!-- FALLAX -->
			<article class="works recent" id="fallax">
				<header>
					<h3>Fallax</h3>
					<summary>Animated VR Short <span class="divider">x</span> Funded by Arts Council England</summary>
					<ol>
						<li>2021-current</li>
						<li>Co-director, animator</li>
						<li>Unity, Houdini</li>
					</ol>
				</header>
				<section>
					<section>
						<img src="./images/projects/HiddenWorld-coverDesign.png" alt="vrShort-portfolio" width="610"
									height="400" class="alignleft" />
					</section>
					<section>
						<p>This short film in VR is an spin-off project from Huldufugl and Hikapee's (equally ambitious) stage show, The Hidden People, after that project was delayed by a year due to the pandemic.</p>
						<p>We've been collaborating with UK aerial circus company Hikapee since 2018 on a large-scale stage production - but when it became apparent that we were going to have to pause work on it for at least a year, we came up with the idea of producing an animated VR short film using the same performers, set in the same world, but with a brand new storyline.</p>
						<p>The first step was to find a motion capture company brave enough to work with tumbling, spinning circus performers using silks, trapeze and counterbalancing equipment - a real challenge for the tracking system - and then do the entire thing on location, whilst adhering to strict COVID-19 safety measures.</p>
						<p>We were extremely lucky to find a partner in Target3D, who sent an incredible crew to join our artists in isolation at 101 Outdoor Arts in Newbury for a week. Under Bryony from Hikapee's direction, they recorded an entire narrative of aerial circus-infused action.</p>
					</section>
					<section>
						<p>The film is currently under production with all the virtual sets, characters, lighting and composition currently under way.</p>
						<p>It's a unique challenge to produce animated work for VR - where almost anything is possible in terms of angles, lighting, sound and set design. For our piece, we're taking a lot of cues from theatre over film in terms of set layout and the audience's relationship to the performers - but this still leaves us a huge possibility space to play with, which is extremely exciting!</p>
						<p>We're also aiming for a unique art style that represents the Icelandic nature - acheived through procedural modelling in Houdini, taking the rough outlines of landscapes, and 'shredding' them into thousands of small, individually coloured polygons. This approach retains sharp edges in VR even up-close, without using textures, whilst also giving us fine control over colour, pre-baked static lighting, and vertex shader effects like wind movement in trees, water and moss.</p>
						<p>Release is scheduled for early 2022, for Oculus Quest and other major VR platforms.</p>                   
					</section>
					<section>
						<ul>
							<li>Hikapee Circus Theatre : <a href="http://www.hikapeetheatre.com/" target="_blank">➩</a></li>
							<li>Target3D : <a href="https://www.target3d.co.uk/" target="_blank">➩</a></li>
							<li>Aerial Performer Jen Robinson : <a href="https://www.jenrobinsonperformance.com/" target="_blank">➩</a></li>
							<li>Aerial Performer Katie Hardwick : <a href="https://www.katiehardwick.com/" target="_blank">➩</a></li>
							<li>Music & Sound by Iris Thorarins : <a href="https://www.facebook.com/iristhorarins/" target="_blank">➩</a></li>
						</ul>
					</section>
				</section>
			</article>

			<!-- LAMBCHILD SUPERSTAR -->
			<article class="collaboration" id="lambchild">
				<header>
					<h3>Oculus Studios : Lambchild Superstar</h3>
					<summary>VR Music Creation Experience<span class="divider">x</span> Oculus Studios, OKGO &amp; Within</summary>
					<ol>
						<li>2017-2021</li>
						<li>Lead Developer</li>
						<li>Unity</li>
					</ol>
				</header>
				<section>
					<img src="./images/projects/lcs-lemmings.png" alt="lcs-portfolio" width="610"
					class="alignleft" />
					<section>
						<p> In 2017, my studio Horizons (along with co-founder Yuli Levtov and David Li) were approached by Chris Milk and Aaron Koblin's VR powerhouse Within to help them develop an incredibly ambitious VR project in collaboration with Oculus Studios, and the musical / creative force of OKGO.</p>
						<p>The task was to create an experience in VR where the user could produce their very own pop song, complete with drums, bass, guitar, synth, vocals (recorded and auto-tuned by the user!) and a special cow-based freestyle solo instrument.</p>
						<p>The final piece includes a staggering amount of layers of animation, machine learning, audio analysis and processing, a custom sound engine, hand interaction and musical theory.</p>						
					</section>
					<section>
						<h6>Engaget Coverage :</h6>
						<iframe width="auto" src="https://www.youtube.com/embed/Wk9JCkVscJY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
					</section>
					<section>
						<p>In 2018 we were very excited to give the world a peek of the final piece, at both Tribeca Film Festival and Sonar+ in Barcelona.</p>
						<p>Two audience members at a time, carefully guided by white-coated docents, could collaborate on building a song together in a purpose-built booth. The piece attracted a significant amount of positive attention, being described as 'Social VR's Rock Band' by Wired, and others.</p>
						<p>My role as lead developer ranged from prototyping musical interaction concepts at the start of the project, to co-ordinating the fantastic development team across several different cities and time zones, overseeing the asset pipeline of animated creatures from the art team into Unity, and working directly on various parts of the project.</p>
						<p>We're excited for the final public release of the project, to see the music people make in the Menagerie of the Holy Cow!</p>
					</section>
					<section>
						<ul>
							<li>Within : <a href="https://www.with.in/" target="_blank">➩</a></li>
							<li>OKGO : <a href="https://okgo.net/" target="_blank">➩</a></li>
							<li>Horizons Studio: <a href="https://horizons.studio/" target="_blank">➩</a></li>
							<li>Oculus Studios: <a href="https://www.oculus.com/story-studio/" target="_blank">➩</a></li>						   
						</ul>
					</section>
				</section>
			</article>

			<!-- LAST NIGHT OF AN EMPIRE-->
			<article class="collaboration" id="lnoae">
				<header>
					<h3>Imogen Heap : Last Night Of An Empire</h3>
					<summary>AR Music Video<span class="divider">x</span> Imogen Heap &amp; Volta</summary>
					<ol>
						<li>April 2021</li>
						<li>VFX, Development</li>
						<li>Unity, Houdini</li>
					</ol>
				</header>
				<section>
					<section>
						<img src="./images/projects/ih-lnoae-03_looping.gif" alt="lnoae-portfolio" width="610"
						height="auto" class="alignleft" />
					</section>
					<section>
						<p>During my time with Volta, we were thrilled to collaborate with world-renowned musician and innovator Imogen Heap to create the official video for her single Last Night Of An Empire.</p>
								
						<p>Volta had at that point been developing its AR capabilities, particularly by integrating Keijiro Takahashi's Rcam2 library, which allowed us to easily integrate a real camera feed from a LIDAR-equipped iPad with 3D objects and visuals generated in Unity, and be able to freely move the camera around the space.</p>
							
						<p>True to her experimental and open spirit, Imogen decided that the recording of the video would also be live-streamed, meaning everything from the camera movment to AR visual effects and Imogen's choreography were repeated and refined over and over again and streamed to Youtube, whilst we searched for the perfect take.</p>
							
						<p>Imogen's loyal legion of Heapsters provided encouragement and comment via the stream, and after just over three hours, the final take was in the bag. But it didn't end there - we also produced a standalone VR-only version of the video to be included as an archived performance inside of Volta.</p>
						
					</section>
					<section>
						<p>Ahead of the recording at Imogen's barn studio space in Essex, I got to work creating visual elements in Houdini + Unity, and exposing parameters for on-set creative technologist Alexis Michallek to hook up to the Ableton session running the show so he could choreograph the AR visuals in time with the playback.</p>
								
						<p>For the VR version, along with several new visual effects, I built several extensions to the Unity Timeline system to allow me to work quickly with the existing Volta setup and create a tightly synced experience (separate to the livestreamed video).</p>
							
						<p>The VR video is unfortunately only available inside Volta VR, but you can catch a 2D recording of it <strong><a href="https://drive.google.com/file/d/11PpR73vVSiCCLG0utNBfiqbgnB5jljt8/view?usp=sharing" target="_blank">here</a></strong></p>          
					</section>
					<section>
						<ul>
							<li>Volta : <a href="https://volta-xr.com/" target="_blank">➩</a></li>
							<li>Official Video : <a href="https://www.youtube.com/watch?v=OenBCfdRtws" target="_blank">➩</a></li>
							<li>Mini-documentary : <a href="https://www.youtube.com/watch?v=JrrHli-34_g" target="_blank">➩</a></li>
							<li>Livestreamed making-of recording : <a href="https://www.youtube.com/watch?v=ijLtHHPE09k" target="_blank">➩</a></li>						   
						</ul>
					</section>
				</section>
			</article>

			<!-- THE HIDDEN PEOPLE -->
			<article class="works recent" id="hidden-people">				
				<header>
					<h3>The Hidden People</h3>
					<summary>Aerial Circus Show<span class="divider">x</span> Hikapee Theatre &amp; Huldufugl</summary>
					<ol>
						<li>2018-2022</li>
						<li>Co-director, Visual designer</li>
						<li>Unity, TouchDesigner, Houdini</li>
					</ol>
				</header>
				<section>
					<section>
						<iframe width="auto" src="https://www.youtube.com/embed/40yw2HdOKJk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
					</section>
					<section>
						<p>A collaboration between Hikapee Theatre and Huldufugl, The Hidden People is a show for medium to large stages (500 capacity+) that combines Icelandic folklore, circus/ aerial arts, performance and creative technology.</p>
						<p>Our story concerns the Hidden People, beings of uncertain benevolence often held responsible in Icelandic stories for both sudden good fortune and disappearances, unexpected occurrences and madness.</p>
						<p>We are using these tales to present modern environmental issues, specifically the building of hydroelectric dams in Iceland.</p>						
					</section>
					<section>
						<p>Hikapee approached us at Huldufugl to collaborate on this piece, and for us to join our skills with creative technology to their high-flying aerial storytelling abilities.</p>
						<p>During the research and development process, we experimented with different technologies to animate this world - and settled on large-scale projection mapping, using both the set and the performers themselves as a canvas</p>
						<p>We ended up having projected visuals for the entire duration of the show (90 minutes). I used Houdini and Unity to model and render the scenes, working in realtime during rehearsals, then rendering out high-resolution HAP video for playback in most cases, with a few scenes exported as live Unity apps, controlled with an Xbox gamepad live during shows, which is still a little nerve-racking!</p>
						<p>Playback was handled using a large custom-made TouchDesigner setup, responding to OSC from Qlab, and handling realtime post-effects such as ripples, and mapping the two projectors onto the stage.</p>
						<p>Finally, after several years of rehearsals, covid-induced delays and fundraising, the world premiere took place at Worthing Pavilion Theatre in March 2022. The show plans to be touring worldwide from August 2022.</p>          
					</section>
					<section>
						<ul>
							<li>Show information: <a href="http://huldufugl.is/hiddenpeople" target="_blank">➩</a></li>
							<li>Hikapee Circus Theatre : <a href="http://www.hikapeetheatre.com/" target="_blank">➩</a></li>
						</ul>
					</section>
				</section>
			</article>

			<!-- OUT OF SYNC -->
			<article class="works recent" id="out-of-sync">
				<header>
					<h3>Out Of Sync</h3>
					<summary>AR Livestream Performance</summary>
					<ol>
						<li>Nov 2020</li>
						<li>Development, VJ</li>
						<li>Unity, TouchDesigner</li>
					</ol>
				</header>
				<section>
					<section>
						<iframe width="610" height="400"
						src="https://www.youtube.com/embed/_6tcQovdPQQ?modestbranding=1&#038;showinfo=0&#038;rel=0"
						frameborder="0" allowfullscreen></iframe>
					</section>
					<section>
						<p>Out Of Sync is a mad idea, an experimental performance formed in response to the
							COVID-19 pandemic. So obviously in 2020 many artists across the world are unable to
							perform to audiences of more than a handful of people (at best), and those countries
							where audiences <em>can</em> gather in numbers have achieved this largely through
							(sensibly) strict border restrictions, meaning they are unable to invite
							international artists to come and play. In addition to this, the global climate
							crisis remains &#8211; albeit backgrounded a bit by the pandemic. 
						</p>
						<p>The idea is that a performer in Iceland (at the time gatherings were limited to 10
							people or fewer) would live-stream to a club in Taipei, Taiwan. There, a full
							audience of dancing people (Taiwan had no gathering restrictions at the time) would
							enjoy the party. However, we had two dancers, or &#8220;eyes&#8221; inside the club,
							using mobile phones to provide a two-way video stream <em>back</em> to Reykjavik,
							where two people at a time would experience the party on the other side of the world
							inside large wooden booths specially built for the purpose.</p>
						
					</section>
					<section>
						<ul>
							<li><strong>Event Production :</strong> Uta Reichardt, René Boonekamp, Aephie Chen</li>
							<li><strong>AR Graphics :</strong> Owen Hindley &#038; Yuli Levtov (Volta)</li>
							<li><strong>Performer :</strong> <a href="https://hermigervill.bandcamp.com/" target="_blank">Hermigervill / Sveinbjörn Thorarensen</a></li>
							<li><strong>Camera :</strong> Yuli Levtov, Uta Reichardt</li>
							<li><strong>Video Editing &#038; Titles :</strong> Owen Hindley</li>
						</ul>
					</section>
					<section>
						<p>Now a 90 minute performance, regardless of how great the music is or colourful his
							onesie is, might not be the most visually interesting experience if it was
							a simple camera setup. Luckily, I had been working for several months with my
							long-suffering collaborator Yuli Levtov on an exciting new project called Volta,
							which aims to make it easy for performing artists to create visually engaging
							livestream experiences, either for 2d video streaming or in VR.</p>
						<p>Even more luckily, the month before, we had integrated Keijiro Takahashi&#8217;s
							outstanding Rcam2 system into Volta&#8217;s existing visual system, allowing us to
							do a full AR performance using only an iPad Pro and a laptop running Unity + Touch
							Designer.</p>
						<p>We're super happy with the results, which you can watch above, and excited to
							see where this new medium can take us. Since then we&#8217;ve incorporated a
							user-facing editor into the Volta product, which you can read more about below. In
							addition, this same team has applied to produce several more events during 2021 to
							investigate alternate means of performance and audience experience &#8211; both as
							the world recovers from the pandemic, and as we look forwards to ways to reduce the
							burden of extensive travel on artists wanting to perform outside of their home
							countries, whilst still making it a party!</p>          
					</section>
					<section>
						<ul>
							<li>Project page : <a href="http://outof-sync.com"
								target="_blank">➩</a></li>
							<li>Volta : <a href="https://volta-xr.com/" target="_blank">➩</a></li>
							<li>Rcam2 page : <a href="https://github.com/keijiro/Rcam2"
								target="_blank">➩</a></li>
						<ul>
					</section>
					
				</section>
			</article>

		</main>
	</div>
	<div id="contentArea" class="container">
		<div id="contentList">
			<div class="grid row">
				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="fallax"></a>
								<h3>UNTITLED VR SHORT</h3>
							</div>
							<div class="caption four columns">
								<h6>2021-2022</h6>
								<h6>Co-director, Design & VFX</h6>
								<h6>Unity, Houdini</h6>
							</div>
							<div class="details twelve columns">
								<h6>Animated VR Short <span class="divider">x</span> Funded by Arts Council England
								</h6>
							</div>
						</div>
						<div class="row">
							<div class="twelve columns">
								<img src="./images/projects/HiddenWorld-coverDesign.png" alt="vrShort-portfolio" width="610"
								height="400" class="alignleft" />
							</div>
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								This short film in VR is an spin-off project from Huldufugl and Hikapee's (equally ambitious) stage show, The Hidden People, after that project was delayed by a year due to the pandemic.
								
								We've been collaborating with UK aerial circus company Hikapee since 2018 on a large-scale stage production - but when it became apparent that we were going to have to pause work on it for at least a year, we came up with the idea of producing an animated VR short film using the same performers, set in the same world, but with a brand new storyline.
								
								The first step was to find a motion capture company brave enough to work with tumbling, spinning circus performers using silks, trapeze and counterbalancing equipment - a real challenge for the tracking system - and then do the entire thing on location, whilst adhering to strict COVID-19 safety measures.
								
								We were extremely lucky to find a partner in Target3D, who sent an incredible crew to join our artists in isolation at 101 Outdoor Arts in Newbury for a week. Under Bryony from Hikapee's direction, they recorded an entire narrative of aerial circus-infused action.
								
								
							</div>
							<div class="bodyTextCol six columns">
								The film is currently under production with all the virtual sets, characters, lighting and composition currently under way.
								
								It's a unique challenge to produce animated work for VR - where almost anything is possible in terms of angles, lighting, sound and set design. For our piece, we're taking a lot of cues from theatre over film in terms of set layout and the audience's relationship to the performers - but this still leaves us a huge possibility space to play with, which is extremely exciting!
								
								We're also aiming for a unique art style that represents the Icelandic nature - acheived through procedural modelling in Houdini, taking the rough outlines of landscapes, and 'shredding' them into thousands of small, individually coloured polygons. This approach retains sharp edges in VR even up-close, without using textures, whilst also giving us fine control over colour, pre-baked static lighting, and vertex shader effects like wind movement in trees, water and moss.
								
								Release is scheduled for early 2022, for Oculus Quest and other major VR platforms.
								
								<div class="links">
									<strong>Hikapee Circus Theatre : <a href="http://www.hikapeetheatre.com/" target="_blank">➩</a></strong>
									<strong>Target3D : <a href="https://www.target3d.co.uk/" target="_blank">➩</a></strong>
									<strong>Aerial Performer Jen Robinson : <a href="https://www.jenrobinsonperformance.com/" target="_blank">➩</a></strong>
									<strong>Aerial Performer Katie Hardwick : <a href="https://www.katiehardwick.com/" target="_blank">➩</a></strong>
									<strong>Music & Sound by Iris Thorarins : <a href="https://www.facebook.com/iristhorarins/" target="_blank">➩</a></strong>
								</div>
							</div>
						</div>
					</div>


				</div>
				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="lambchild-superstar"></a>
								<h3>LAMBCHILD SUPERSTAR</h3>
								
							</div>
							<div class="caption four columns">
								<h6>2017-2021</h6>
								<h6>Lead Developer</h6>
								<h6>Unity</h6>
							</div>
							<div class="details twelve columns">
								<h6>VR Music Creation Experience <span class="divider">x</span> Oculus Studios, Within &amp; OKGO
								</h6>
							</div>
						</div>
						<div class="row">
							<div class="twelve columns">
								<img src="./images/projects/lcs-lemmings.png" alt="lcs-portfolio" width="610"
								 class="alignleft" />
							</div>
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								In 2017, my studio Horizons (along with co-founder Yuli Levtov and David Li) were approached by Chris Milk and Aaron Koblin's VR powerhouse Within to help them develop an incredibly ambitious VR project in collaboration with Oculus Studios, and the musical / creative force of OKGO.
								
								The task was to create an experience in VR where the user could produce their very own pop song, complete with drums, bass, guitar, synth, vocals (recorded and auto-tuned by the user!) and a special cow-based freestyle solo instrument.
								
								The final piece includes a staggering amount of layers of animation, machine learning, audio analysis and processing, a custom sound engine, hand interaction and musical theory.
								
								<strong>Engaget Coverage :</strong>
								
								<iframe width="auto" src="https://www.youtube.com/embed/Wk9JCkVscJY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
								
							</div>
							<div class="bodyTextCol six columns">
								In 2018 we were very excited to give the world a peek of the final piece, at both Tribeca Film Festival and Sonar+ in Barcelona.
								
								Two audience members at a time, carefully guided by white-coated docents, could collaborate on building a song together in a purpose-built booth. The piece attracted a significant amount of positive attention, being described as 'Social VR's Rock Band' by Wired, and others.
								
								My role as lead developer ranged from prototyping musical interaction concepts at the start of the project, to co-ordinating the fantastic development team across several different cities and time zones, overseeing the asset pipeline of animated creatures from the art team into Unity, and working directly on various parts of the project.
								
								We're excited for the final public release of the project, to see the music people make in the Menagerie of the Holy Cow!
								
								<div class="links">
								<strong>Within : <a href="https://www.with.in/" target="_blank">➩</a></strong>
								<strong>OKGO : <a href="https://okgo.net/" target="_blank">➩</a></strong>
								<strong>Horizons Studio: <a href="https://horizons.studio/" target="_blank">➩</a></strong>
								<strong>Oculus Studios: <a href="https://www.oculus.com/story-studio/" target="_blank">➩</a></strong>
							</div>
							</div>
						</div>
					</div>
				</div>

			</div>
			<div class="grid row">
				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="imogen-heap-last-night-of-an-empire"></a>
								<h3>LAST NIGHT OF AN EMPIRE</h3>
								
							</div>
							<div class="caption four columns">
								<h6>April 2021</h6>
								<h6>Design & VFX</h6>
								<h6>Unity, Houdini</h6>
							</div>
							<div class="details twelve columns">
								<h6>AR Music Video <span class="divider">x</span> Imogen Heap &amp; Volta
								</h6>
							</div>
						</div>
						<div class="row">
							<div class="twelve columns">
								<img src="./images/projects/ih-lnoae-03_looping.gif" alt="lnoae-portfolio" width="610"
								height="auto" class="alignleft" />
							</div>
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								During my time with Volta, we were thrilled to collaborate with world-renowned musician and innovator Imogen Heap to create the official video for her single Last Night Of An Empire.
								
								Volta had at that point been developing its AR capabilities, particularly by integrating Keijiro Takahashi's Rcam2 library, which allowed us to easily integrate a real camera feed from a LIDAR-equipped iPad with 3D objects and visuals generated in Unity, and be able to freely move the camera around the space.
								
								True to her experimental and open spirit, Imogen decided that the recording of the video would also be live-streamed, meaning everything from the camera movment to AR visual effects and Imogen's choreography were repeated and refined over and over again and streamed to Youtube, whilst we searched for the perfect take.
								
								Imogen's loyal legion of Heapsters provided encouragement and comment via the stream, and after just over three hours, the final take was in the bag. But it didn't end there - we also produced a standalone VR-only version of the video to be included as an archived performance inside of Volta.
								
								
							</div>
							<div class="bodyTextCol six columns">
								Ahead of the recording at Imogen's barn studio space in Essex, I got to work creating visual elements in Houdini + Unity, and exposing parameters for on-set creative technologist Alexis Michallek to hook up to the Ableton session running the show so he could choreograph the AR visuals in time with the playback.
								
								For the VR version, along with several new visual effects, I built several extensions to the Unity Timeline system to allow me to work quickly with the existing Volta setup and create a tightly synced experience (separate to the livestreamed video).
								
								The VR video is unfortunately only available inside Volta VR, but you can catch a 2D recording of it <strong></strong><a href="https://drive.google.com/file/d/11PpR73vVSiCCLG0utNBfiqbgnB5jljt8/view?usp=sharing" target="_blank">here</a></strong>
								
								<div class="links">
								<strong>Volta : <a href="https://volta-xr.com/" target="_blank">➩</a></strong>
								<strong>Official Video : <a href="https://www.youtube.com/watch?v=OenBCfdRtws" target="_blank">➩</a></strong>
								<strong>Mini-documentary : <a href="https://www.youtube.com/watch?v=JrrHli-34_g" target="_blank">➩</a></strong>
								<strong>Livestreamed making-of recording : <a href="https://www.youtube.com/watch?v=ijLtHHPE09k" target="_blank">➩</a></strong>
							</div>
							</div>
						</div>
					</div>


				</div>
				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="hidden-people"></a>
								<h3>THE HIDDEN PEOPLE</h3>
								
							</div>
							<div class="caption four columns">
								<h6>2018 onwards</h6>
								<h6>VFX</h6>
								<h6>Unity, TouchDesigner</h6>
							</div>
							<div class="details twelve columns">
								<h6>Aerial Circus Show Projections <span class="divider">x</span> Hikapee Theatre &amp; Huldufugl
								</h6>
							</div>
						</div>
						<div class="row">
							<div class="twelve columns">
								<img src="./images/projects/hidden-people.jpg" alt="hiddenPeople-portfolio" width="610"
								 class="alignleft" />
							</div>
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								A collaboration between Hikapee Theatre and Huldufugl, The Hidden People is a brand new show that combines Icelandic folklore, circus/ aerial arts, performance and creative technology.
								
								Our story concerns the Hidden People, beings of uncertain benevolence often held responsible in Icelandic stories for both sudden good fortune and disappearances, unexpected occurrences and madness.
								
								We are using these tales to present modern environmental issues, specifically the building of hydroelectric dams in Iceland.
																
								
							</div>
							<div class="bodyTextCol six columns">
								Hikapee approached us at Huldufugl to collaborate on this piece, and for us to join our skills with creative technology to their high-flying aerial storytelling abilities.
								
								We have completed two stages of research and development (R&D). The first of which consisted of two weeks in Iceland in December 2018, and two in the UK in February 2019, culminating in a sharing at Jacksons Lane Theatre in March 2019. The second saw us return to Jacksons Lane in August 2019, and head to Helsinki in January 2020.
								
								<div class="links">
								<strong>Hikapee Circus Theatre : <a href="http://www.hikapeetheatre.com/" target="_blank">➩</a></strong>
								<strong>Show Teaser 1: <a href="https://www.youtube.com/watch?v=wS6en3Gbh08" target="_blank">➩</a></strong>
								<strong>Show Teaser 2: <a href="https://www.youtube.com/watch?v=PI8tR-2kBIs" target="_blank">➩</a></strong>
							</div>
							</div>
						</div>
					</div>
				</div>

			</div>

			<div class="grid row">
				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="out-of-sync"></a>
								<h3>OUT OF SYNC</h3>
								
							</div>
							<div class="caption four columns">
								<h6>Nov 2020</h6>
								<h6>Development, VJ</h6>
								<h6>Unity</h6>
							</div>
							<div class="details twelve columns">
								<h6>AR Livestream Performance <span class="divider">x</span> Independent Project
								</h6>
							</div>
						</div>
						<div class="row">
							<div class="twelve columns">
								<iframe width="610" height="400"
									src="https://www.youtube.com/embed/_6tcQovdPQQ?modestbranding=1&#038;showinfo=0&#038;rel=0"
									frameborder="0" allowfullscreen></iframe>
							</div>
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								Out Of Sync is a mad idea, an experimental performance formed in response to the
								COVID-19 pandemic. So obviously in 2020 many artists across the world are unable to
								perform to audiences of more than a handful of people (at best), and those countries
								where audiences <em>can</em> gather in numbers have achieved this largely through
								(sensibly) strict border restrictions, meaning they are unable to invite
								international artists to come and play. In addition to this, the global climate
								crisis remains &#8211; albeit backgrounded a bit by the pandemic. 
								The idea is that a performer in Iceland (at the time gatherings were limited to 10
								people or fewer) would live-stream to a club in Taipei, Taiwan. There, a full
								audience of dancing people (Taiwan had no gathering restrictions at the time) would
								enjoy the party. However, we had two dancers, or &#8220;eyes&#8221; inside the club,
								using mobile phones to provide a two-way video stream <em>back</em> to Reykjavik,
								where two people at a time would experience the party on the other side of the world
								inside large wooden booths specially built for the purpose.
								<strong>Event Production :</strong> Uta Reichardt, René Boonekamp, Aephie Chen
								<strong>AR Graphics :</strong> Owen Hindley &#038; Yuli Levtov (Volta)
								<strong>Performer :</strong> <a href="https://hermigervill.bandcamp.com/"
									target="_blank">Hermigervill / Sveinbjörn Thorarensen</a>
								<strong>Camera :</strong> Yuli Levtov, Uta Reichardt
								<strong>Video Editing &#038; Titles :</strong> Owen Hindley
							</div>
							<div class="bodyTextCol six columns">
								Now a 90 minute performance, regardless of how great the music is or colourful his
								onesie is, might not be the most visually interesting experience if it was
								a simple camera setup. Luckily, I had been working for several months with my
								long-suffering collaborator Yuli Levtov on an exciting new project called Volta,
								which aims to make it easy for performing artists to create visually engaging
								livestream experiences, either for 2d video streaming or in VR.
								Even more luckily, the month before, we had integrated Keijiro Takahashi&#8217;s
								outstanding Rcam2 system into Volta&#8217;s existing visual system, allowing us to
								do a full AR performance using only an iPad Pro and a laptop running Unity + Touch
								Designer.
								We&#8217;re super happy with the results, which you can watch above, and excited to
								see where this new medium can take us. Since then we&#8217;ve incorporated a
								user-facing editor into the Volta product, which you can read more about below. In
								addition, this same team has applied to produce several more events during 2021 to
								investigate alternate means of performance and audience experience &#8211; both as
								the world recovers from the pandemic, and as we look forwards to ways to reduce the
								burden of extensive travel on artists wanting to perform outside of their home
								countries, whilst still making it a party!
								<div class="links">
								<strong>Project page : <a href="http://outof-sync.com"
										target="_blank">➩</a></strong>
								<strong>Volta : <a href="https://volta-xr.com/" target="_blank">➩</a></strong>
								<strong>Rcam2 page : <a href="https://github.com/keijiro/Rcam2"
										target="_blank">➩</a></strong>
								
							</div>
							</div>
						</div>
					</div>


				</div>
				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="kassinn"></a>
								<h3>KASSINN/A BOX IN THE DESERT</h3>
								
							</div>
							<div class="caption four columns">
								<h6>2017-18</h6>
								<h6>Direction, Design, Development</h6>
								<h6>Unity, VR</h6>
							</div>
							<div class="details twelve columns">
								<h6>Interactive VR theatre <span class="divider">x</span> Huldufugl</h6>
							</div>
						</div>
						<div class="row">
							<iframe width="610" height="400"
								src="https://www.youtube.com/embed/1N8qWTjxVdc?modestbranding=1&#038;showinfo=0&#038;rel=0"
								frameborder="0" allowfullscreen></iframe>
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								<em>Imagine one day, you wake up inside an invisible box, unable to escape. Kassinn
									is an engaging, but playful, interactive theatre performance with a live actor
									in virtual reality. Will you trust this mysterious stranger? Or listen to the
									voice in your head, trying to get you out?</em>
								Created by Huldufugl (an Icelandic / British events company co-founded by myself and
								writer, actress &amp; producer Nanna Gunnars), the show explores what I&#8217;ve
								been wanting to do for a long time, smashing together future-thinking theatre forms
								with technology &#8211; in this case, Virtual Reality and mutliplayer
								gaming!
								<div class="links">
								<strong>Performers :</strong> Nanna Gunnars, Ástþór Ágústsson
								<strong>Music :</strong> <a href="https://www.facebook.com/iristhorarins/"
									target="_blank">Iris Thorarins</a>
								<strong>Sound :</strong> <a href="http://reactifymusic.com" target="_blank">Ragnar
									Hrafnkelsson</a>
								<strong>Concept Development :</strong> Alexander Dan Vilhjálmsson
								<strong>Additional 3D design, build :</strong> Jacob Andersson
								
								<strong>Behind the scenes at STOFF 2018 : </strong><a
									href="https://www.youtube.com/watch?v=iknyVDuHfRE&#038;t=1s"
									target="_blank">➩</a>
								<strong>Kassinn at Menningarnótt 2017 (first iteration) : </strong><a
									href="https://www.youtube.com/watch?v=14xuXcE5ht8" target="_blank">➩</a>
								
								<strong>WINNER : Best Interactive Narrative Experience <a
										href="https://www.raindance.org/raindance-immersive-award-winners-presented-by-bose/"
										target="_blank">Raindance Film Festival 2019</a></strong>
								<strong>WINNER : Outstanding USA Premiere, <a href="https://sdfringe.org/"
										target="_blank">San Diego International Fringe Festival
										2019</a></strong>
								<strong>WINNER : Most Amazing Game Award 2019, <a
										href="https://amazestuff.tumblr.com/post/184139013534/a-maze-berlin-2019-award-winners"
										target="_blank">A MAZE. Festival 2019</a></strong>
								<strong>WINNER : Innovation in Performance, <a href="http://www.stockholmfringe.com/"
										target="_blank">Stockholm
										International Fringe Festival 2018</a></strong>
								<strong>NOMINATED : GRAND PRIX, <a href="http://www.stockholmfringe.com/"
										target="_blank">Stockholm International Fringe Festival
										2018</a></strong>
									</div>
								<img src="./images/projects/RVKFringe-Award-SoldOut-2018-white-xsmall.png"
									width="120" />
								<img src="./images/projects/stoff-2018-awards-ceremony-logo-white-2-768x369-290x139.png"
									width="110" style="margin-top:-3px" />
							</div>
							<div class="bodyTextCol six columns">
								The concept initially began as a short play by Nanna, written and performed in a
								conventional theatre in 2016 &#8211; after which I put forward the idea to re-create
								this piece in VR. We premiered the first version in Reykjavík in August 2017, and
								developed it for a longer run in July 2018, before taking the show to the Stockholm
								Fringe Festival in September 2018, and with more international dates planned for
								2019!
								One person at a time experiences the piece inside of a 2 x 2m physical space, whilst
								the actor performs in a separate physical space. For our first outing, we used the
								Xsens motion capture suit (expertly handled by <a href="http://puppit.is"
									target="_blank">PuppIT</a>), but currently the show involves two Oculus Rift
								setups, sharing the same virtual space using multiplayer networking.
								Show control is handled by an operator, who can observe and control both events in
								the world and the &#8216;voice in your head&#8217; via a Qlab interface, and we have
								a beautiful LED box created by Swedish engineering magicians <a
									href="http://svartljus.se" target="_blank">Svartljus</a>
								<div class="links">
								<strong>Huldufugl project page : <a href="http://huldufugl.is/kassinn"
										target="_blank">➩</a></strong>
								
							</div>
							</div>
						</div>
					</div>


				</div>
			</div>
			<div class="grid row">
				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="gale"></a>
								<h3>G A L E</h3>
								
							</div>
							<div class="caption four columns">
								<h6>2019</h6>
								<h6>Design, Music</h6>
								<h6>Unity</h6>
							</div>
							<div class="details twelve columns">
								<h6>Isle Of Games <span class="divider">x</span> Personal project</h6>
							</div>
						</div>
						<div class="row">
							<img src="./images/projects/gale3-portfolio.jpg" alt="gale3-portfolio" width="610"
								height="374" class="alignleft" />
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								A short platform experience about using the wind to guide your way.
								Originally created for the Isle of Games 002 (see isleofgames.is) exhibition on the
								theme of &#8220;The Tempest&#8221;, the player is making their way through a pitch
								black world, with nothing but the wind to guide their path. 
								The installation version was for two people to cooperate, one using a joystick to
								control the character, the other using rotating lava rock + button to control the
								wind. This version is just controlled using the keyboard.

								<strong>Credits:</strong>
								Design &amp; Music by Owen Hindley
								Character controller magic by @torfias
								Feedback and general advice from @joonturbo, Sig Gunnarsson and the rest of the Isle
								of Games team.


							</div>
							<div class="bodyTextCol six columns">
								<div class="links">
								Game can be downloaded from <a href="https://owenhindley.itch.io/gale"
									target="_blank">** itch.io **</a></strong>
								
							</div>
							</div>
						</div>
					</div>


				</div>
				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="unconfined"></a>
								<h3>UNCONFINED</h3>
								
							</div>
							<div class="caption four columns">
								<h6>April 2017</h6>
								<h6>Unity</h6>
								<h6>Development</h6>
							</div>
							<div class="details twelve columns">
								<h6>Samsung &amp; Universal Everything <span class="divider">x</span> Interactive
									pavilion installation</h6>
							</div>
						</div>
						<div class="row">
							<iframe
								src="https://player.vimeo.com/video/212285861?color=ffffff&#038;title=0&#038;byline=0&#038;portrait=0"
								width="610" height="343" frameborder="0" webkitallowfullscreen mozallowfullscreen
								allowfullscreen style="margin-bottom:3em;"></iframe>
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								Unconfined is an immersive interactive installation by
								Universal Everything and Zaha Hadid Architects commissioned by Samsung Mobile and
								unveiled at Milan Design Week 2017, to accompany the launch of the new Galaxy S8
								phone.
								
								So I&#8217;ve been a massive fanboy of Universal Everything&#8217;s work ever since
								Matt Pyke formed the studio post-Designers Republic, so being invited to join them
								as a developer on this adventure was a bit exciting, to say the least!
								The brief was to produce a real-time, interactive artwork that would be projected
								onto seven monumental &#8216;petals&#8217;, designed and inhabiting a space by Zaha
								Hadid Architects, within a relatively short timeframe &#8211; and with a lot of
								press attention on the final result, so no small order.
								
								<div class="links">
								Concept &amp; creative direction by <a
									href="http://universaleverything.com/projects/unconfined/" target="_blank">Universal
									Everything</a>
								Lead Developer : <a href="http://chrismullany.com/" target="_blank">Chris
									Mullany</a>
								Additional Development : <a href="http://poniesandlight.co.uk/" target="_blank">Ponies
									And Light</a>
								Architects : <a href="http://www.zaha-hadid.com/" target="_blank">Zaha
									Hadid</a>
								</div>
							</div>
							<div class="bodyTextCol six columns">
								With a tight timeline, the lead developer Chris Mullany and I developed a system for
								simulating choreographed bird-like motion onto thousands of unique
								&#8216;avatars&#8217; &#8211; playful, generative striped characters who would fly
								and dance around the space.
								We worked rapidly in Unity, with Chris handling the creation and rendering of the
								Avatars, and me handling the flocking motion and choreographies that would play in
								synchronicity with composed music from Simon Pyke / Freefarm.
								The final setup in Milan required an impressive assortment of hardware, handled by
								an amazing crew of projectionists, d3 operators, sound and lighting designers, and
								our playback rig &#8211; 6 high-end PCs running Unity apps, all synchronised via
								network from a single server, from which we could adjust and refine all aspects of
								the show once we arrived in Milan.
								
								<div class="links">
								Press :
								<a href="http://www.designboom.com/design/zaha-hadid-architects-samsung-unconfined-installation-milan-design-week-04-05-2017/"
									target="_blank">Designboom</a>
								<a href="https://hypebeast.com/2017/4/zaha-hadid-architects-samsung-unconfined-digital-art-installation"
									target="_blank">Hype Beast</a>
								<a href="https://www.designweek.co.uk/inspiration/unconfined-galaxy-s8-design-universal-everything-zaha-hadid-architects-samsung/"
									target="_blank">Design Week</a>
								</div>

							</div>
						</div>
					</div>


				</div>
			</div>
			<div class="grid row">
				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="bonobo-outlier-vr"></a>
								<h3>BONOBO OUTLIER VR</h3>
							   
							</div>
							<div class="caption four columns">
								<h6>June 2017</h6>
								<h6>Design, Development</h6>
								<h6>Unity, C4D</h6>
							</div>
							<div class="details twelve columns">
								<h6>Interactive VR Music Journey <span class="divider">x</span> Google Daydream</h6>
							</div>
						</div>
						<div class="row">
							<iframe width="610" height="400"
								src="https://www.youtube.com/embed/w_WFJPYgWfU?modestbranding=1&#038;showinfo=0&#038;rel=0"
								frameborder="0" allowfullscreen></iframe>
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">In collaboration with Ninja Tune heavyweight artist
								Bonobo, the
								Horizons team (Yuli Levtov, David Li, Leif Podhajsky and myself) saddled up again to
								create a brand new psychedelic interactive music journey for the Horizons platform
								on Google Daydream.
								
								The new scene features the track Outlier from his latest album Migration, and allows
								you to deeply interact with the music, which in turn has an effect on the landscape
								you fly through. Flocks of birds join you on your journey through sand dunes,
								towering mountains and beneath the waves.
								
							</div>
							<div class="bodyTextCol six columns">
								<div class="links">
								<strong>Press :</strong>
								<a href="http://cdm.link/2017/06/bonobo-have-turned-a-track-into-a-tranquil-trippy-vr-journey/"
									target="_blank">Create Digital Music</a>
								<a href="http://www.techradar.com/news/vr-killed-the-video-star-new-interactive-experience-is-a-next-gen-music-video"
									target="_blank">Tech Radar</a>
								</div>
							</div>
						</div>
					</div>


				</div>
				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="horizons-vr"></a>
								<h3>HORIZONS VR</h3>
								
							</div>
							<div class="caption four columns">
								<h6>2016</h6>
								<h6>Design, Development</h6>
								<h6>Unity, C4D, Houdini</h6>
							</div>
							<div class="details twelve columns">
								<h6>Interactive VR Music Journeys <span class="divider">x</span> Google Daydream
								</h6>
							</div>
						</div>
						<div class="row">
							<iframe
								src="https://player.vimeo.com/video/265810162?color=ffffff&#038;title=0&#038;byline=0&#038;portrait=0"
								width="610" height="343" frameborder="0" webkitallowfullscreen mozallowfullscreen
								allowfullscreen></iframe>
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								Horizons is a series of interactive VR music journeys for
								Google Daydream, available for free on the Play Store.
								
								After a chance introduction in Iceland via the wonderful people at <a
									href="http://www.bedroomcommunity.net/">Bedroom Community</a>, I was invited to
								submit a proposal for a launch title for Google&#8217;s new VR headset, Daydream. I
								contacted my long-term collaborator Yuli Levtov and together with our friends David
								Li and Leif Podhajsky, we laid out plans to create the first music-focused title for
								this new platform.

								
								<div class="links">
								Created by:
								<a href="http://owenhindley.co.uk" target="_blank">Owen Hindley</a>
								<a href="http://david.li" target="_blank">David Li</a>
								<a href="http://leifpodhajsky.com/" target="_blank">Leif Podhajsky</a>
								<a href="http://reactifymusic.com" target="_blank">Reactify</a>

								
								With incredible support from:
								<a href="http://www.madewithmonsterlove.com/" target="_blank">Peter
									Cardwell-Gardner</a>
								<a href="http://www.richardeflanagan.com/" target="_blank">Richard E Flanagan</a>
							</div>
							</div>
							<div class="bodyTextCol six columns">Within the app, you control the music &#8211; the music
								controls the world. You can use the Daydream controller to make an otherworldly
								jungle come alive with sound, or travel at breakneck speed through colourful
								hyperspace.
								

								In December 2016 we launched the first two scenes, featuring great music from both
								My Panda Shall Fly and Reuben Cainer. We&#8217;re very excited to be launching the
								third scene in early 2017, and there&#8217;s more to come.
								
								<div class="links">
								<strong>Featured in the Raindance VR Arcade 2017:</strong>
								<a href="http://calendar.raindancefestival.org/programmes/vr-arcade"
									target="_blank"><img src="./images/projects/raindance-selection.png"
										alt="raindance-selection" width="150" height="auto" /></a>

								<strong>Press :</strong>
								<a href="https://www.youtube.com/watch?v=CFVUJmlAESs" target="_blank">Daydream
									District Playthrough</a>
								<a href="https://m.reddit.com/r/daydream/comments/5kb8kh/handson_horizons_on_daydream_vr/"
									target="_blank">Reddit</a>
								</div>
							</div>
						</div>
					</div>


				</div>

			</div>
			<div class="grid row">
				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="light-organ"></a>
								<h3>LIGHT ORGAN</h3>
								
							</div>
							<div class="caption four columns">
								<h6>2016</h6>
								<h6>Development</h6>
								<h6>NodeJS, Max/MSP, DMX</h6>
							</div>
							<div class="details twelve columns">
								<h6>Public Installation <span class="divider">x</span> Atli Bollason</h6>
							</div>
						</div>
						<div class="row">
							<iframe
								src="https://player.vimeo.com/video/169834486?title=0&#038;badge=0&#038;byline=0&#038;portrait=0"
								width="610" height="343" frameborder="0" webkitallowfullscreen mozallowfullscreen
								allowfullscreen></iframe>
							
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								<strong>
									HARMONY IS COLOUR.
									PITCH IS POSITION.
									STRENGTH IS BRILLIANCE.
								</strong>
								
								Conceived &amp; produced by Atli Bollason.
								Developed by:
								Yuli Levtov, Reactify
								Ragnar Ingi Hrafnkelsson, Reactify
								Owen Hindley
								Build supervisor:
								Jonas Johansson
							</div>
							<div class="bodyTextSpacer">&nbsp;</div>
							<div class="bodyTextCol six columns">
								For a few days in February 2016, visitors of Harpa Music Hall in Reykjavík were
								invited to play the façade of the building as they would an instrument. A
								&#8220;light organ&#8221; was placed on the 4th floor balcony, with a stunning view
								of the inside of the geometrical glass front and the downtown
								area.Anyone who passed through could learn how to play in blue or red or
								green, with quick flashes or swelling pads of light, and impress the whole city with
								an optical performance.
								
								<div class="links">
								<strong>Press :</strong>
								<a href="https://thecreatorsproject.vice.com/blog/play-a-building-like-an-instrument-reykjavik"
									target="_blank">The Creators Project</a>
								</div>
							</div>
						</div>
					</div>


				</div>

				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="moon-seat"></a>
								<h3>THE MOON SEAT</h3>
							   
							</div>
							<div class="caption four columns">
								<h6>February 2016</h6>
								<h6>Tech lead, sound design</h6>
								<h6>Flash, Processing, JS</h6>
							</div>
							<div class="details twelve columns">
								<h6>Installation art piece <span class="divider">x</span> Alex Jenkins and Owen
									Hindley</h6>
							</div>
						</div>
						<div class="row">
							<img src="./images/projects/moon-seat.jpg" alt="Moon Seat" width="610"/>
							
							<h6>
								<span class="linkArrow">&gt;</span>
								<a href="http://moonseat.tumblr.com/" target="_blank">moonseat.tumblr.com</a>
							</h6>
							
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								The Moon Seat is a playful installation that entertains our inner child whilst
								simultaneously courting long forgotten childhood fears.
								
								The installation had its first public outing at the <strong>e-Luminate</strong>
								festival in Cambridge, UK from 12th-17th February 2016, and was located on the front
								lawn of the prestigious Cambridge Union Society.
								
								Audience members were invited to sit, at which point the pool of moonlight would
								instantly open to show their shadow. After a few seconds, their shadow would
								transform into an animal &#8211; still controlled by their bodily movements, but
								with a character all of its own. An ethereal generative soundtrack reacting to the
								users&#8217; movements accompanies the piece.
							</div>
							<div class="bodyTextSpacer">&nbsp;</div>
							<div class="bodyTextCol six columns">
								I&#8217;d worked with Alex for a long time at B-Reel, and I was very excited to be
								asked to get involved in his first independent installation art piece!
								
								It quickly became apparent that we were going to need some more help, so we drafted
								in ex-B-Reelers and good friends Yi-Wen Lin and Christian Persson to come on board.
								
								We pulled in quite a variety of technologies for this one, including <a
									href="http://processing.org" target="_blank">Processing</a> (main show), <a
									href="http://nwjs.io" target="_blank">NodeWebkit</a> (gesture detection &#038;
								tracking), <a href="http://labs.adobe.com/technologies/flashruntimes/"
									target="_blank">Flash/AIR</a> (character animation &#038; playback) and <a
									href="http://puredata.info/" target="_blank">Pure Data</a> (generative audio
								&#038; DMX control), all talking together over more than 16 OSC channels.
								
								<div class="links">
								Press:
								<strong>The Tab: <a
										href="http://thetab.com/uk/cambridge/2016/02/18/art-installation-inspired-full-moon-placed-outside-union-69233"
										target="_blank">➩</a></strong>
								<strong>The Moon Seat at e-Luminate 2016 : <a
										href="http://www.e-luminatefestivals.co.uk/e-luminate-festival-2016/eventsandinstallations/alexander-jenkins-and-owen-hindley/"
										target="_blank">➩</a></strong>
									</div>
							</div>
						</div>
					</div>


				</div>
			</div>
			<div class="grid row">
				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="mmorph"></a>
								<h3>MMORPH</h3>
								
							</div>
							<div class="caption four columns">
								<h6>February 2016</h6>
								<h6>Lead Development, Design</h6>
								<h6>Javascript/Coffeescript, WebAudio, SVG</h6>
							</div>
							<div class="details twelve columns">
								<h6>Interactive browser-based audio experience <span class="divider">x</span>
									MassiveMusic</h6>
							</div>
						</div>
						<div class="row">
							<img src="./images/projects/Mmorph-screenshot.jpg" alt="mmorph by MassiveMusic" width="610"
								height="374" />
							<h6>
								<span class="linkArrow">&gt;</span>
								<a href="http://mmorph.massivemusic.com" target="_blank">mmorph.massivemusic.com</a>
							</h6>
							<h6>
								<span class="linkArrow">&gt;</span>
								<a href="https://vimeo.com/154044120" target="_blank">Case Study Video</a>
							</h6>
							
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								mmorph is an adventure into new ways of delivering interactive music in the browser
								and beyond.
								
								A collaboration between global music agency MassiveMusic, Reactify Music, Grotesk,
								Enzien Audio and myself, mmorph is an example of a new workflow which we hope will
								open up many possibilities for interactive audio &#8211; first in the browser, and
								then for games, apps, installations and VR.
								The site takes you through an interactive music piece, enabling different musical
								parts, applying realtime effects, composing and looping a top-line synth, and
								creating intense build-ups and drops!
								
								<div class="links">
								<strong>MassiveMusic: <a href="http://www.massivemusic.com/"
										target="_blank">➩</a></strong>
								<strong>Reactify: <a href="http://reactifymusic.com/"
										target="_blank">➩</a></strong>
								<strong>Enzien Audio: <a href="https://enzienaudio.com/"
										target="_blank">➩</a></strong>
								<strong>Grotesk Studio: <a href="http://groteskstudio.com/"
										target="_blank">➩</a></strong>
							</div>
							</div>
							<div class="bodyTextSpacer">&nbsp;</div>
							<div class="bodyTextCol six columns">
								My role was lead developer on the project, handling the integration of the audio
								code from Reactify &#038; Enzien Audio (who in turn were working with original music
								composed by Massive) with realtime SVG graphics and animations art-directed by
								Grotesk.
								
								The interactive audio was produced via a unique workflow where Reactify worked
								rapidly and closely with Massive&#8217;s in-house composer in Pure Data, an visual
								programming environment that allows for real-time prototyping and development.
								
								This Pure Data &#8216;patch&#8217; was then converted to run in the browser via
								Enzien Audio&#8217;s <strong>Heavy</strong> compiler. This compiler can also
								transform the same source patch into code suitable for Unity, Unreal engine,
								OpenFrameworks, desktop/mobile apps and VR experiences, with little or no
								alterations to the original.
								
								<div class="links">
								Awards:
								<strong>FWA PCA of The Year (Nomination): <a
										href="https://thefwa.com/editorial/the-fwa-peoples-choice-award-pca-2016-vote-now"
										target="_blank">➩</a></br></strong>
								<strong>FWA Site of The Month: <a href="http://www.thefwa.com/site/mmorph"
										target="_blank">➩</a></strong>
								<strong>Awwwards Honorable Mention: <a
										href="http://www.awwwards.com/best-websites/mmorph/"
										target="_blank">➩</a>
										<strong>FWA Insights: <a href="http://www.thefwa.com/article/insights-mmorph"
											target="_blank">➩</a></strong>
								</strong>
							</div>
							</div>
						</div>
					</div>


				</div>

				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="htc-vive-launch"></a>
								<h3>HTC VIVE LAUNCH</h3>
								
							</div>
							<div class="caption four columns">
								<h6>February 2016</h6>
								<h6>Lead Developer</h6>
								<h6>Javascript/ES6, WebGL, WebAudio</h6>
							</div>
							<div class="details twelve columns">
								<h6>Online WebGL experience <span class="divider">x</span> HTC / Google / B-Reel
								</h6>
							</div>
						</div>
						<div class="row">
							<iframe
								src="https://player.vimeo.com/video/163678193?color=ffffff&#038;title=0&#038;byline=0&#038;portrait=0"
								width="610" height="360" frameborder="0" webkitallowfullscreen mozallowfullscreen
								allowfullscreen></iframe>
							
							<h6>
								<span class="linkArrow">&gt;</span>
								<a href="http://viveready.htcvr.com" target="_blank">viveready.htcvr.com</a>
							</h6>
							
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								Get Vive Ready by HTC, Google and B-Reel is a WebGL experience that invites the user
								to test if they are &#8216;Vive&nbsp;Ready&#8217;, to promote the launch of
								HTC&#8217;s Vive VR headset.
								
								The site uses a mobile device as a controller for the 3D desktop experience, and
								requires you to chop, dodge, swing and shake your way through four challenging
								levels.

							</div>
							<div class="bodyTextSpacer">&nbsp;</div>
							<div class="bodyTextCol six columns">
								Users completing all four levels were able to enter a prize draw to win an actual
								Vive headset and controller set.
								
								The site involves some cutting-edge WebGL and mobile phone interaction, which we
								were happy to see recognised in a number of awards including the FWA&#8217;s site of
								the Month (which followed our project Mmorph&#8217;s award the previous month!)
								
								<div class="links">
								Awards:
								<strong>FWA PCA of The Year (Nomination): <a
										href="https://thefwa.com/editorial/the-fwa-peoples-choice-award-pca-2016-vote-now"
										target="_blank">➩</a></br></strong>
								<strong>FWA Site of The Month: <a
										href="http://www.thefwa.com/site/get-vive-ready?c=SOTM"
										target="_blank">➩</a></strong>
								<strong>Awwards SOTD : <a href="http://www.awwwards.com/sites/get-vive-ready"
										target="_blank">➩</a></strong>
								</div>
							</div>
						</div>
					</div>


				</div>
			</div>
			<div class="grid row">
				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="sonar-visuals"></a>
								<h3>SÓNAR VISUALS</h3>
								
							</div>
							<div class="caption four columns">
								<h6>Ongoing</h6>
								<h6>Design, Mgmt, Development</h6>
								<h6>Javascript, Node.js, DMX</h6>
							</div>
							<div class="details twelve columns">
								<h6>Massive realtime generative visuals <span class="divider">x</span> Sónar
									Festival Reykjavik</h6>
							</div>
						</div>
						<div class="row">
							<iframe width="610" height="343"
								src="https://www.youtube.com/embed/m53kuvMLAiY?modestbranding=1&#038;showinfo=0&#038;rel=0"
								frameborder="0" allowfullscreen></iframe>
							
							<h6>
								<span class="linkArrow">&gt;</span>
								<a href="https://vimeo.com/161909071" target="_blank">Watch 2016 Video</a>
							</h6>
							
							<h6>
								<span class="linkArrow">&gt;</span>
								<a href="https://vimeo.com/122900808" target="_blank">Watch 2015 Video</a>
							</h6>
							
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								Sónar is an international festival of progressive music and multimedia arts,
								originally out of Barcelona, but now taking place in several locations worldwide,
								including Reykjavik since 2013.
								It is hosted in the landmark building Harpa, a beautiful structure with a unique
								interlocking cell-like front facade (designed by Olafur Eliasson) each containing an
								LED light fixture. Combined it forms a large outdoor screen that is visible across
								much of downtown Reykjavik.
								
								Artist Atli Bollasson and I were lucky enough to be the first outside artists to do
								something on this facade in 2014, with the publicly-playable arcade game <a
									href="http://www.owenhindley.co.uk/harpa-pong/">Harpa PONG</a> at
								Reykjavík&#8217;s Culture night.
								After the success of PONG, Harpa and the Sónar organisers invited Atli and myself to
								do a repeat installation on the lights of Harpa for the festival in 2015, and again
								in 2016.
								
								
								<div class="links">
								Links:
								<strong>HarpaPONG: <a href="http://harpapong.com/"
										target="_blank">➩</a></strong>
								<strong>Sónar Reykjavik: <a href="http://sonarreykjavik.com/"
										target="_blank">➩</a></strong>
								<strong>Harpa: <a href="http://harpa.is/" target="_blank">➩</a></strong>
								Press:
								<strong>Festival Insights: <a
										href="http://www.festivalinsights.com/2015/02/sonar-reykjavik-transforming-facades/"
										target="_blank">➩</a></strong>
								<strong>VjSpain: (Spanish) <a
										href="http://vjspain.com/blog/2015/02/19/atli-bollason-y-owen-hindley-en-el-sonar-reykjavik-2015/"
										target="_blank">➩</a></strong>
								<strong>Yi-Wen Lin (visuals collaborator) process blog post : <a
										href="http://blog.bongiovi.tw/harpapong-challenge-of-400-pixels/"
										target="_blank">➩</a></strong>
							   
							 </div>
							</div>
							<div class="bodyTextSpacer">&nbsp;</div>
							<div class="bodyTextCol six columns">
								We knew we wanted to do a bit more than simply re-run PONG, so instead we decided
								&#8211; in addition to running the game &#8211; we would turn the entire building
								into an audio-reactive light show, taking the music being played inside and use it
								to drive the visuals outside.
								
								To do this we reached out to other creative developers, providing them with a code
								framework, brief, and challenge to do something amazing with only 36 x 11 pixels. We
								ended up with over 12 functioning visual responses from 8 developers from around
								Europe, which was way beyond our expectations.
								
								<!-- The results can be seen in the video above, for three days the visuals were bouncing around to the likes of Skrillex, Todd Terje and Elliphant, and were attracting attention not only in the city of Reykjavik, but also (we happily realised) inside the venue as well, where we accidentally became the main lightshow for the SonarPub stage. -->
							   
							</div>
						</div>
					</div>


				</div>

				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="pringles-pinatas"></a>
								<h3>SMASHING PIÑATAS</h3>
								
							</div>
							<div class="caption four columns">
								<h6>Summer 2015</h6>
								<h6>Electronics, Design, Build</h6>
								<h6>Node.js</h6>
							</div>
							<div class="details twelve columns">
								<h6>Physical robot design & build <span class="divider">x</span> Isobar UK / B-Reel
									London</h6>
							</div>
						</div>
						<div class="row">
							<iframe
								src="https://player.vimeo.com/video/135659303?title=0&#038;badge=0&#038;byline=0&#038;portrait=0"
								width="610" height="343" frameborder="0" webkitallowfullscreen mozallowfullscreen
								allowfullscreen></iframe>
							
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								International agency Isobar collaborated with B-Reel and Groovy Gecko to create a
								live, web-connected experience that allowed users to smash a real-life piñata using
								a robotic arm, in order to promote the new flavours of Pringles
								Tortillas.
								Users in the UK and Germany were able to sign up via Twitter and/or Facebook to take
								a hit at the unlucky piñata, successful entrants would win a Tortillas-related
								prize!
							</div>

							<div class="bodyTextCol six columns">
								B-Reel approached me to lead the design and build of the robotic arm &#8211; a
								really fun challenge!
								This required a lot of research into fabrication methods, and learning about
								pneumatics for the first time, combined with electronic control (via <a
									href="http://www.phidgets.com/" target="_blank">Phidgets</a>) and backend
								development to connect the entire system to the website (being developed by
								Isobar)
								After constructing two beautiful robots (Pedro &#038; Mario, in reserve), we to work
								smashing piñatas, the arm pounding each one with 20psi of force per hit. Over 40
								piñatas a day were obliterated live online, in a custom-built Mexican marketplace
								set deep within East London.
								
								<div class="links">
								Links:
								<strong>Isobar casestudy:</strong> <a
									href="http://www.isobar.fr/uk/insights/detail/isobar-creates-smart-innovative-tech-to-launch-the-new-pringles-tortilla-chips"
									target="_blank">➩</a>
								<strong>B-Reel casestudy:</strong> <a
									href="http://films.b-reel.com/projects/digital/case/895/pringles-pinata/"
									target="_blank">➩</a>
								</div>
							</div>
						</div>
					</div>


				</div>
			</div>
			<div class="grid row">
				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="city-of-drones"></a>
								<h3>CITY OF DRONES</h3>
								
							</div>
							<div class="caption four columns">
								<h6>Summer 2014</h6>
								<h6>Audio + Physics, Sound Design</h6>
								<h6>WebGL, WebAudio, Dart</h6>
							</div>
							<div class="details twelve columns">
								<h6>Immersive online experience / installation <span class="divider">x</span>
									Barbican / FIELD.IO</h6>
							</div>
						</div>
						<div class="row">
							<iframe
								src="//player.vimeo.com/video/100417527?title=0&amp;byline=0&amp;portrait=0&amp;color=ffffff"
								width="610" height="343" frameborder="0" webkitallowfullscreen mozallowfullscreen
								allowfullscreen></iframe>
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								City of Drones is an interactive digital environment developed by musician John
								Cale, speculative architect Liam Young and digital artists FIELD. Charting the story
								of a lost drone drifting through an abstract cityscape, players are invited to pilot
								a virtual craft and remotely explore this imaginary world. Samples from Cale’s
								original soundscape compositions echo across the landscape as we see the city
								through the eyes of the drone, buzzing between the buildings, drifting endlessly, in
								an ambient audio visual choreography.
								City of Drones lives online, and as an installation at the Barbican Center, London,
								as part of the Digital Revolution exhibition.
								
								<div class="links">
								<strong>Field.io : <a href="http://www.field.io" target="_blank">➩</a></strong>
								<strong>Liam Young : <a href="http://www.tomorrowsthoughtstoday.com/"
										target="_blank">➩</a></strong>
								<strong>John Cale: <a href="http://john-cale.com/"
										target="_blank">➩</a></strong>
								<strong>BXFTYS: <a href="http://www.boxoftoysaudio.com/"
										target="_blank">➩</a></strong>
									</div>
							</div>
							<div class="bodyTextCol six columns">
								I was brought on to the project to develop the dynamic audio of the piece with the
								team at FIELD. This involved remixing original material from John Cale, including
								bespoke work from BXFTYS, and setting it all in a constantly changing, immersive 3D
								sonic landscape.
								
								Spot sound effects are triggered by different locations within the environment, and
								the sounds of drones as they fly past are processed using the WebAudio HRTF panner
								to accurately position the sounds in 3D space.
								
								The background music layer and ambience also change as you fly through the different
								areas.
								
								In addition, I also contributed to the physics of the drones, giving them some
								freedom of movement as they fly around the space, avoiding buildings and each other,
								plus I developed the on-screen HUD graphics and animation.

							</div>
						</div>
					</div>


				</div>

				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="spectra-2"></a>
								<h3>SPECTRA 2</h3>
								
							</div>
							<div class="caption four columns">
								<h6>Summer 2014</h6>
								<h6>Electronics, Build, Install</h6>
								<h6>Arduino, Node.js</h6>
							</div>
							<div class="details twelve columns">
								<h6>Kinectic Sculpture <span class="divider">x</span> FIELD.io / Accept & Proceed
								</h6>
							</div>
						</div>
						<div class="row">
							<img src="./images/projects/spectra-cover.jpg" alt="spectra-cover" width="610"
								height="auto" />
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								Spectra 2, a mesmerising kinetic sculpture by FIELD.io in collaboration with design
								studio Accept &#038; Proceed was displayed in the studio&#8217;s East London gallery
								space in Summer 2014.
								The piece consists of suspended polished steel segments, controlled by stepper
								motors &#038; custom electronics, that form rippling terrains inspired by NASA lunar
								meteor impact data.
								
								<div class="links">
								<strong>Field.io : <a href="https://www.field.io/project/spectra-2/"
										target="_blank">project page</a></strong>
								<strong>Accept &#038; Proceed : <a href="http://acceptandproceed.com/"
										target="_blank">➩</a></strong>
								<strong>Laurence Symonds : <a href="http://http://laurencesymonds.wordpress.com//"
										target="_blank">➩</a></strong>
								<strong>Edu Prats Molner (jocabola) : <a href="http://www.jocabola.com/"
										target="_blank">➩</a></strong>
										Press:<br/>
										<strong>Creators Project : <a
											href="https://thecreatorsproject.vice.com/en_uk/blog/meteor-impacts-on-the-moon-drive-this-elegant-kinetic-sculpture"
											target="_blank">article</a></strong>
									</div>
							</div>
							<div class="bodyTextCol six columns">
								Collaborating with lead engineer Laurence Symonds, FIELD and A&#038;P, I was
								responsible for the design &#038; implementation of the motor software control
								system, which played back a pre-choreographed sequence (pre-visualised and designed
								in Houdini by FIELD).
								I was also very happy to be part of the superhuman build, test &#038;
								installation team.
								
								Custom Arduino firmware and a unique serial protocol needed to be developed in order
								to synchronise movement across all 48 motors for the duration of the hour-plus long
								sequence. A Node.js server was written to handle playback and synchronisation with a
								wall-mounted display, and triggering of audio samples via OSC.
							   
							</div>
						</div>
					</div>


				</div>
			</div>
			<div class="grid row">
				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="harpa-pong"></a>
								<h3>PLAY PONG ON HARPA</h3>
								
							</div>
							<div class="caption four columns">
								<h6>August 2014</h6>
								<h6>Design, Development</h6>
								<h6>Node.js, DMX, HTML5</h6>
							</div>
							<div class="details twelve columns">
								<h6>Massive outdoor game <span class="divider">x</span> Harpa Concert & Conference
									Center, Reykjavik</h6>
							</div>
						</div>
						<div class="row">
							<iframe width="610" height="343"
								src="//www.youtube.com/embed/R3_OSTtyfSw?modestbranding=1&#038;showinfo=0&#038;rel=0"
								frameborder="0" allowfullscreen></iframe>
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								PONG is a massive interactive outdoor artwork that allows two people to play the
								classic game against each other on the monumental facade of Harpa, Iceland&#8217;s
								flagship concert hall in downtown Reykjavik, designed by Ólafur Eliasson.
								
								Conceived and produced by Atli Bollason, the project began as a chance meeting
								between myself and Atli at a birthday party in Reykjavik, and over the next few
								months developed into a reality &#8211; with not only the CEO of the building coming
								on board very quickly, but for the first time for a project like this, Ólafur
								himself (the first time he has allowed a project like this to take over the
								facade&#8217;s lighting system). Vodafone Iceland also agreed to sponsor the
								project, and supply us with some of the equipment.
								
								The project was launched on Menningarnótt (Culture Night) on the 23rd August 2014,
								and ran for a week afterwards as part of the Reykjavik Dance Festival. 
								For the launch night, we setup a stage in front of the building, and players used a
								pair of phones to control their &#8216;paddles&#8217; on the 43m-high screen.
								Afterwards, players were able to join a special Wi-fi network which took them
								directly to the game, which was transmitted from a hill overlooking the building.
								This would allow them to join a virtual queue, and play against friends or complete
								strangers.
							</div>
							<div class="bodyTextCol six columns">
								Our roles were split with Atli handling the concept, creative direction, project
								management and publicity, and me handling the design, hardware, networking and
								programming.
								
								Three separate Node.js servers run together to create the experience; one running in
								the basement of Harpa which outputs DMX to control the 35&#215;11 pixel display (6
								universes of 512 channels each), one running in the cloud which actually simulates
								the game physics, and receives WebSocket connections from the player&#8217;s phone,
								and another which handles the game queue.
								
								An HTML5 mobile front-end was also developed to give visual feedback to the player
								of their paddle, and current score.
								
								The code for the entire project is available on github:
								<div class="links">
								<strong>Github : <a
										href="https://github.com/owenhindley/harpapong">github.com/owenhindley/harpapong</a></strong>
										<strong>Homepage : <a href="http://harpapong.com"
											target="_blank">➩</a></strong>
									<strong>Menningarnótt site (Icelandic) : <a href="http://menningarnott.is/pong-horpu"
											target="_blank">➩</a></strong>
											
								Press:
								<strong>Reykjavik Grapevine : <a
										href="http://grapevine.is/culture/art/2014/08/30/go-pong-harpa-now/"
										target="_blank">➩</a></strong>
								<strong>Iceland Magazine: <a
										href="http://www.icelandmag.com/article/playing-pong-harpas-concert-hall-43-61-meter-light-wall"
										target="_blank">➩</a></strong>
									</div>
							</div>
						</div>
					</div>


				</div>

				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="resonate-music"></a>
								<h3>RESONATE '15 MUSIC</h3>
								
							</div>
							<div class="caption four columns">
								<h6>Jan 2015</h6>
								<h6>Music composition</h6>
								<h6>Sound design</h6>
							</div>
							<div class="details twelve columns">
								<h6>Music Composition & Sound Design <span class="divider">x</span> Resonate
									Festival / FIELD.io</h6>
							</div>
						</div>
						<div class="row">
							<iframe
								src="//player.vimeo.com/video/118132518?color=ffffff&#038;title=0&#038;byline=0&#038;portrait=0"
								width="610" height="343" frameborder="0" webkitallowfullscreen mozallowfullscreen
								allowfullscreen></iframe>
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								Resonate is a festival that brings together artists to drive a forward-looking
								debate on the position of technology in art and culture.
								Held annually in Belgrade, Serbia, it draws visual artists, programmers, performers,
								musicians and curators to present and discuss their work, share new ideas, work and
								party hard.
								<!-- The graphic identity for the 2015 festival was developed by the Resonate team and FIELD.io, and is described as NEON TRIBAL PLAYGROUND CULTURE - and it informed the direction for all graphic, web and motion design relating to the festival.-->
								
								For the trailer, FIELD collaborated with director / designer Antar Walker to bring
								their graphic identity for the festival into motion.
							</div>
							<div class="bodyTextCol six columns">
								I was approached by FIELD to collaborate with the team on the musical score and
								sound design for the piece.
								<!-- The brief was to produce something as playful, human, optimistic but still contemporary as the identity itself, incorporating tribal sounds and percussion whilst still retaining an air of exploration and ambition.-->
								
								I immediately brought my long-suffering friend and collaborator Ragnar Hrafnkelsson
								on board, and together we composed, mixed and mastered the final soundtrack.
								
								In addition to receiving considerable coverage online, the trailer was also aired on
								Serbian national TV in the run-up to the festival opening.
								
								<div class="links">
								Links / Press:
								<strong>Resonate Festival: <a href="http://resonate.io"
										target="_blank">➩</a></strong>
								<strong>Ragnar Hrafnkelsson / Reactify Music: <a href="http://reactifymusic.com"
										target="_blank">➩</a></strong>
								<strong>Antar Walker: <a href="http://rgblust.com/"
										target="_blank">➩</a></strong>
								<strong>FIELD.io: <a href="http://field.io" target="_blank">➩</a></strong>
							</div>
							</div>
						</div>
					</div>


				</div>
			</div>
			<div class="grid row">
				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="like-noones-watching"></a>
								<h3>LIKE NO-ONE'S WATCHING</h3>
								
							</div>
							<div class="caption four columns">
								<h6>March 2014</h6>
								<h6>Devising, design</h6>
								<h6>Ableton, QLab</h6>
							</div>
							<div class="details twelve columns">
								<h6>Personal project <span class="divider">x</span> Barbican OpenLAB, Rose Bruford
								</h6>
							</div>
						</div>
						<div class="row">
							<iframe width="610" height="344" src="https://www.youtube.com/embed/UCIUfXuJTw4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								Audience members are invited into a space and given wireless
								headphones.
								We then turn out the lights, allowing their non-visual senses to become heightened,
								and their concerns about &#8216;who&#8217;s watching?&#8217; to gently
								dissipate.
								We live in a world in which, although our minds are able to travel virtually great
								distances daily, our bodies can often fall into a routine of the same movements of
								waking, dressing, commuting to work, sitting in front of a computer &#8211; all day,
								every day.
								
								This is in parallel with an increase in visual stimulation &#8211; brightly coloured
								billboards, TV, magazines, fashion &#8211; whereas our other senses, touch, smell,
								and most importantly hearing (with the exception of music, which we use to shut out
								the world), often get left behind.
								Our work plays with both of these ideas, creating an environment where the audience
								is able to relax in their own space, and concentrate on different sensory
								experiences.
								To enjoy freedom of movement both through direct instruction and abstract
								inspiration.
								Like no-one&#8217;s watching.
								
								By:
								Owen Hindley, Ragnar Hrafnkelsson, Nanna Gunnars &amp; Brynja Herbertsdóttir
							</div>
							<div class="bodyTextCol six columns">
								This was a piece created in three short days in conjunction the Barbican&#8217;s
								OpenLAB programme.
								Taking place in the black box theatre, deep in the base of the sprawling Barbican
								estate, we wanted to take advantage of the near-complete darkness we could achieve,
								coupled with access to the technical equipment on-site, and the theatrical
								experience of Brynja &amp; Nanna.
								What emerged out of the three days was a prototype-form show, lasting around twenty
								minutes, involving multi-channel audio playback to individual&#8217;s headphones
								(which we used to create magic moments like &#8216;touch based hearing&#8217;),
								playing with clashing and coherent smells / sounds, polyrhythmic clapping exercises,
								and finally a session in led movement resulting in wild abandon!
								
								We were able to spy the performance (which took place in pitch darkness) via a
								series of infra-red cameras and illuminators feeding to backstage, in order to
								properly time auditory cues and effects.
								
								<div class="links">
								Project website : <a href="http://tidydino.com/noonewatching/" target="_blank">Like
									No-one&#8217;s Watching</a>
								</div>
							</div>
						</div>
					</div>


				</div>

				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="xbox-glitch"></a>
								<h3>XBOX GLITCH</h3>
							   
							</div>
							<div class="caption four columns">
								<h6>2014</h6>
								<h6>Technical lead, Sound Design</h6>
								<h6>HTML5, PHP, LAMP Administration</h6>
							</div>
							<div class="details twelve columns">
								<h6>Online ARG / Cryptic competition <span class="divider">x</span> B-Reel / CP+B /
									XBox</h6>
							</div>
						</div>
						<div class="row">
							<iframe width="610" height="343"
								src="//www.youtube.com/embed/AKwskqLIVI0?modestbranding=1&#038;showinfo=0&#038;rel=0"
								frameborder="0" allowfullscreen></iframe>
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								&#8216;The Glitch&#8217; was a highly secretive and unusual campaign launched by
								Microsoft, CP+B and B-Reel that took players on a journey across the Internet,
								challenging them to solve puzzles and crack codes to win a mysterious
								prize.
								This formed part of the UK XBox One launch, and part of Microsoft&#8217;s effort to
								engage directly with hardcore gamers by working on their level.
								The glitch took the form of a 1 second &#8216;disruption&#8217; to the Xbox TV
								collaboration that had already been on regular rotation on UK TV channels for some
								time. Hidden within this were a number of codes and clues that would set players off
								on their journey.
								
								<div class="links">
								<strong>B-Reel : <a href="http://www.b-reel.com" target="_blank">➩</a></strong>
								<strong>CP+B London : <a href="http://www.cpbgroup.com/"
										target="_blank">➩</a></strong>
									</div>
							</div>
							<div class="bodyTextCol six columns">
								I headed up the development side of the project team at B-Reel, and was responsible
								for laying out this network of cryptic sites across the web in such a way as to give
								no clue as to who, or what was behind the Glitch. 
								A sophisticated PHP backend system was built to monitor and control all the various
								endpoints to allow tracking of players as they moved through the contest, and
								shutting off routes as soon as prizes had been awarded.
								In addition, I was also responsible for the glitched-up sound design across all of
								the routes, which added to the air of mystery and suspense surrounding the
								campaign. Or, in the words of one contestant, making them
								&#8216;literally shit his pants&#8217;.

							</div>
						</div>
					</div>


				</div>
			</div>
			<div class="grid row">
				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="kuafu"></a>
								<h3>KUAFU</h3>
								
							</div>
							<div class="caption four columns">
								<h6>2013/4</h6>
								<h6>Sound Design, Music, Weather API</h6>
								<h6>Pure Data, Ableton Live, Node.js</h6>
							</div>
							<div class="details twelve columns">
								<h6>Interactive art installation <span class="divider">x</span> Collaboration w/
									Yi-Wen Lin, Bertrand Carrara</h6>
							</div>
						</div>
						<div class="row">
							<img src="./images/projects/kuafu-cover-image.jpg" alt="kuafu-cover-image" width="610"
								height="auto" />
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								Kuafu is an interactive art installation based on the Chinese myth of the giant that
								tried to catch the Sun.
								The installation itself comprises of a large, wide-format projection of a 3d
								landscape, through which the Giant walks, braving weather, mountains, and seas in
								his quest to catch the Sun which is causing a drought amongst his
								people.
								The topography, rivers, oceans and weather are all based on actual data drawn in
								from live APIs and Google Maps, and visitors can control his path using a mounted
								tablet running a web-based interface showing where in the world Kuafu is
								walking.
								I joined the fantastic Yi-Wen Lin and Bertrand Cararra on this project in part as an
								entry for Google&#8217;s DevArt competition, in which we made it through to the
								final 10 entrants!
							</div>
							<div class="bodyTextCol six columns">
								My role on this project was as sound designer and composer, but as you can see from
								the development diary below, we intended to involve as much generative, code-based
								audio as possible in this project to fit with the 3D aesthetic in the visuals. This
								will involve extensive work in Pure Data, as well as controlling Ableton Live via
								OSC from Node.js.
								I also worked on the Weather API, translating the incoming latitude/longitude
								coordinates from the visual engine into data concerning wind speed, direction, and
								rainfall, so our Giant would have to face the same elements as he would do in the
								real world at that location!Also I managed the initial motion capture
								sessions with live actors to give Kuafu some real personality in his movements.
								
								You can see the development process here:
								<div class="links">
								<strong>Project page : <a href="http://cargocollective.com/kuafu"
										target="_blank">➩</a></strong>
								<strong>Project page on DevArt : <a
										href="https://devart.withgoogle.com/#/project/17570645"
										target="_blank">➩</a></strong>
								<strong>Yi-Wen Lin : <a href="http://blog.bongiovi.tw/"
										target="_blank">➩</a></strong>
								<strong>Bertrand Cararra : <a href="http://www.bertrandcarrara.com/"
										target="_blank">➩</a></strong>
									</div>
							</div>
							
						</div>
					</div>


				</div>

				<div class="story six columns">
					<div class="storyBody">
						<div class="storyHeader row">
							<div class="caption eight columns">
								<a name="dynamics"></a>
								<h3>DYNAMICS</h3>
								
							</div>
							<div class="caption four columns">
								<h6>2014</h6>
								<h6>Design, Concepting, Mobile & Server dev</h6>
								<h6>HTML5, Websockets, Node.js</h6>
							</div>
							<div class="details twelve columns">
								<h6>Interactive social music installation <span class="divider">x</span>
									Collaboration with Reactify for DevArt</h6>
							</div>
						</div>
						<div class="row">
							<img src="./images/projects/Dynamics-cards-screenshots-small.jpg"
								alt="Dynamics-cards-screenshots-small" width="610" height="269" />
							
							
							<h6>
								<span class="linkArrow">&gt;</span>
								<a href="https://www.youtube.com/watch?v=zZllSadcf-k" target="_blank">Watch
									Video</a>
							</h6>
						</div>
						<div class="row">
							<div class="bodyTextCol six columns">
								Dynamics is an installation comprised of a room of constantly evolving, generative
								and reactive music, lights and visuals that visitors can interact with via their
								smartphones. Upon joining the installation&#8217;s Wi-Fi network, every
								visitor is presented with a slightly different interface on their smartphones, each
								with a different level or type of influence over their surroundings. The interaction
								types will be various, ranging from being able to trigger short sounds, through to
								changing the overall mood of the music. Some interfaces will encourage interaction
								with other visitors, prompting teamwork and social (as well as musical)
								interaction.
								Yuli (from Reactify Music) and I developed this project in part as an entry for
								Google&#8217;s DevArt competition.
							</div>
							<div class="bodyTextCol six columns">
								We collaborated closely on this project, with him mostly looking after the music and
								lights programming, and myself taking care of the node.js server and mobile
								interface design/development.
								
								You can see the development process here, along with more videos and audio
								demos:
								<div class="links">
								<strong>Project page on DevArt : <a
										href="https://devart.withgoogle.com/#/project/16992761?q=Dynamics"
										target="_blank">➩</a></strong>
								<strong>Reactify : <a href="http://reactifymusic.com/" target="_blank">➩</a></strong>
							</div>
							</div>
							
						</div>
					</div>


				</div>
			</div>

			
			© <h6>Owen Hindley 2022</h6>
		</div>
		&nbsp;

</body>

</html>
